# @package _global_

# specify here default configuration
# order of defaults determines the order in which configs override each other
defaults:
  - conflearn: overlook
  - paths: default
  - data: coco
  - model: retinanet
  - callbacks: default
  - logger: wandb # set logger here or use command line (e.g. `python train.py logger=tensorboard`)
  - trainer: gpu
  - _self_ # If the new behavior works for your application, append _self_ to the end of the Defaults List.
           # If your application requires the previous behavior, insert _self_ as the first item in your Defaults List. 

# seed for random number generators in pytorch, numpy and python.random
seed: 42
num_folds: 4
task_name: chocoball
num_epochs: 12
alpha: 0.1
badloc_min_confidence: 0.5
min_confidence: 0.95
pooling: true
softmin_temperature: 0.1 

paths:
  data_root_dir: /datasets/conflearn/det/chocoball

data: 
  batch_size: 16
  train_transform:
    _target_: src.transforms.detection.DetectionPresetTrain
    data_augmentation: hflip # or multiscale
  
  valid_transform:
    _target_: src.transforms.detection.DetectionPresetEval

  test_transform:
    _target_: src.transforms.detection.DetectionPresetEval
  
  noise_type: ${conflearn.noise_type}
  noise_config: ${conflearn.noise_config}


model:
  optimizer:
    lr: 0.0001
    weight_decay: 0.001
  
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: ${num_epochs}
    eta_min: 0
    last_epoch: -1
  
  trainable_backbone_layers: 5
  compile: true
  # kwargs for retinanet_fpn
  score_thresh: 0.05
  nms_thresh: 0.5
  detections_per_img: 100
  fg_iou_thresh: 0.5
  bg_iou_thresh: 0.4
  topk_candidates: 1000

logger:
  project: confident-learning
  tags: [detection, retinanet, "${task_name}", "${data.noise_type}"]
  save_dir: ${paths.root_dir}/outputs

trainer:
  max_epochs: ${num_epochs}
  deterministic: true
  num_sanity_val_steps: 0
  precision: 16-mixed
  log_every_n_steps: 1