# @package _global_

# specify here default configuration
# order of defaults determines the order in which configs override each other
defaults:
  - paths: default
  - data: coco
  - model: retinanet
  - callbacks: default
  - logger: wandb # set logger here or use command line (e.g. `python train.py logger=tensorboard`)
  - trainer: gpu
  - _self_ # If the new behavior works for your application, append _self_ to the end of the Defaults List.
           # If your application requires the previous behavior, insert _self_ as the first item in your Defaults List. 

# seed for random number generators in pytorch, numpy and python.random
seed: 42
num_folds: 4
task_name: chocoball
num_epochs: 12
alpha: 0.1
badloc_min_confidence: 0.5
min_confidence: 0.95
pooling: true
softmin_temperature: 0.1 

paths:
  root_dir: /workspace
  data_root_dir: /datasets/conflearn/det/chocoball
  log_dir: /workspace/logs
  output_dir: /workspace/outputs

data: 
  batch_size: 16
  train_transform:
    _target_: src.transforms.detection.get_transform
    data_augmentation: hflip # or multiscale
  
  valid_transform:
    _target_: src.transforms.detection.get_transform

  test_transform:
    _target_: src.transforms.detection.get_transform

  # noise_type: overlook
  # noise_config: 
  #   _target_: src.data.cocodetection.OverlookNoiseConfig
  #   prob: 0.1

  # noise_type: badloc
  # noise_config: 
  #   _target_: src.data.cocodetection.BadLocNoiseConfig
  #   prob: 0.1
  #   max_pixel: 100

  noise_type: swap
  noise_config: 
    _target_: src.data.cocodetection.SwapNoiseConfig
    num_classes_to_swap: 3
    prob: 0.1 

model:
  optimizer:
    lr: 0.0001
    weight_decay: 0.001
  
  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    T_max: ${num_epochs}
    eta_min: 0
    last_epoch: -1
  
  trainable_backbone_layers: 5
  compile: true
  # kwargs for retinanet_fpn
  score_thresh: 0.05
  nms_thresh: 0.5
  detections_per_img: 100
  fg_iou_thresh: 0.5
  bg_iou_thresh: 0.4
  topk_candidates: 1000

logger:
  project: confident-learning
  tags: [detection, retinanet, "${task_name}", "${data.noise_type}"]
  save_dir: /workspace/outputs

trainer:
  max_epochs: ${num_epochs}
  deterministic: true
  num_sanity_val_steps: 0
  precision: 16-mixed
  log_every_n_steps: 1
  # fast_dev_run: true